# 作業

## 問題集 #1

完成 Hsieh 書中的 Exercises 4.2、4.3、4.5 和 4.6。

使用資料：
- 4.2: `Winnipeg_DJF_temp.csv`
- 4.5: `SWE_Nino_Nina.csv`
- 4.6: `nino34_long_anom.csv` & `nino12_long_anom.csv`

## 問題集 #2

完成 Hsieh 書中的 Exercises 5.2、5.6、5.7 和 5.9。

使用資料：
- 5.2: `Old_Faithful_geyser.csv`
- 5.6: `Vanc_Tor_Temp_tele.csv`
- 5.7: `Milwaukee_wind_direction_ozone.csv`
- 5.9: `SWE_tele.csv`

## 問題集 #3

完成 Hsieh 書中的 Exercises 6.5、6.6 和 8.1。

使用資料：
- 6.5: `SWE_tele.csv`
- 6.6: `YVR_prcp_training.csv` & `YVR_prcp_testing.csv`

<!-- ## Problem set #4

1. Complete Exercise 12.1 in Hsieh's book.
2. Following the first question, use the support vector machine to classify the forest types in the given dataset. Feel free to choose one-versus-the-rest or one-versus-one approach (and specify your choice). Train using the first two predictors and compare the results with the linear discriminant analysis.
3. Generate a synthetic signal with added noise $y = \sin x + 0.5 \times \mathcal{N}(0, 1)$ and collect 40 data points that are distributed within the range $x = [0, 4\pi]$. Now use (a) ridge regression, (b) kernel ridge regression, and (c) Gaussian progress regression to model the data and give the prediction at the range $x = [0, 8\pi]$ with visualization. Describe and justify your kernel selection and hyperparameter tuning process whenever necessary. Compare the results from three regression methods.

## Problem set #5

Complete the following exercises in Hsieh's book with the specified requirements:

1. Exercise 14.2, including (c)
2. Exercise 12.5, but develop two prediction models instead of one. One of the models must be a random forest or a boosting model.
3. Exercise 14.4, including (b) -->